# CANTUSTORE - AnÃ¡lise de Carrinhos Abandonados

Projeto completo de anÃ¡lise de dados utilizando **Databricks** e **PySpark** para identificar padrÃµes de carrinhos abandonados no e-commerce da CantuStore.

---

## ğŸ“‹ Estrutura do Projeto

```
CantuStore/
â”œâ”€â”€ Parte1_SQL/                      # QuestÃµes SQL da prova
â”‚   â”œâ”€â”€ 1.1_campeonato.sql           # ClassificaÃ§Ã£o de campeonato
â”‚   â”œâ”€â”€ 1.2_comissoes.sql            # AnÃ¡lise de comissÃµes
â”‚   â””â”€â”€ 1.3_colaboradores.sql        # Hierarquia de colaboradores
â”‚
â”œâ”€â”€ Parte2_AnaliseDados/             # AnÃ¡lise de Dados com PySpark
â”‚   â”œâ”€â”€ data/                        # Dados (nÃ£o versionados)
â”‚   â”‚   â”œâ”€â”€ tb_carts/
â”‚   â”‚   â”œâ”€â”€ tb_cartentries/
â”‚   â”‚   â”œâ”€â”€ tb_addresses/
â”‚   â”‚   â”œâ”€â”€ tb_paymentinfos/
â”‚   â”‚   â”œâ”€â”€ tb_users.csv
â”‚   â”‚   â”œâ”€â”€ tb_regions.csv
â”‚   â”‚   â”œâ”€â”€ tb_paymentmodes.csv
â”‚   â”‚   â””â”€â”€ tb_cmssitelp.csv
â”‚   â”‚
â”‚   â””â”€â”€ notebooks/                   # Notebooks PySpark
â”‚       â”œâ”€â”€ 00_setup.py              # ConfiguraÃ§Ã£o inicial
â”‚       â”œâ”€â”€ 01_carregamento_dados.py # Carregamento e validaÃ§Ã£o
â”‚       â”œâ”€â”€ 02_analise_produtos.py   # Produtos mais abandonados
â”‚       â”œâ”€â”€ 03_analise_duplas.py     # Duplas de produtos
â”‚       â”œâ”€â”€ 04_analise_tendencia.py  # TendÃªncia de abandono
â”‚       â”œâ”€â”€ 05_analise_produtos_novos.py  # Produtos novos
â”‚       â”œâ”€â”€ 06_analise_estados.py    # Abandonos por estado
â”‚       â”œâ”€â”€ 07_relatorio_produto_mes.py   # RelatÃ³rio mensal
â”‚       â”œâ”€â”€ 08_relatorio_data.py     # RelatÃ³rio diÃ¡rio
â”‚       â””â”€â”€ 09_exportacao_txt.py     # ExportaÃ§Ã£o TXT
â”‚
â”œâ”€â”€ .gitignore                       # Arquivos ignorados
â””â”€â”€ README.md                        # Este arquivo
```

---

## ğŸ¯ Objetivos do Projeto

### Parte 1: SQL

ResoluÃ§Ã£o de 3 questÃµes usando SQL:
1. âœ… **Campeonato**: ClassificaÃ§Ã£o de times por pontuaÃ§Ã£o
2. âœ… **ComissÃµes**: Vendedores com >= R$ 1.024 em atÃ© 3 transferÃªncias
3. âœ… **Colaboradores**: Identificar chefe indireto mais baixo na hierarquia

### Parte 2: AnÃ¡lise de Dados (PySpark + Databricks)

AnÃ¡lise de carrinhos abandonados respondendo:

**5 AnÃ¡lises ExploratÃ³rias:**
1. âœ… Quais produtos mais tiveram carrinhos abandonados?
2. âœ… Quais duplas de produtos mais foram abandonadas juntas?
3. âœ… Quais produtos tiveram aumento de abandono?
4. âœ… Quais produtos novos e sua performance no primeiro mÃªs?
5. âœ… Quais estados tiveram mais abandonos?

**2 RelatÃ³rios:**
1. âœ… RelatÃ³rio mensal por produto (carrinhos, itens, valor nÃ£o faturado)
2. âœ… RelatÃ³rio diÃ¡rio (carrinhos, itens, valor nÃ£o faturado)

**1 ExportaÃ§Ã£o:**
1. âœ… Arquivo TXT com top 50 carrinhos no formato especificado

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Conta no [Databricks Community Edition](https://community.cloud.databricks.com/)
- Acesso ao GitHub (opcional, para versionamento)

### Passo 1: Configurar Databricks

1. **Criar Cluster:**
   - Acesse: Compute > Create Cluster
   - Runtime: 13.3 LTS ou superior
   - ConfiguraÃ§Ã£o: PadrÃ£o (Community Edition)

2. **Conectar GitHub (Opcional):**
   - Workspace > Repos > Add Repo
   - Clonar este repositÃ³rio

### Passo 2: Upload dos Dados

**OpÃ§Ã£o A - Via UI:**
1. Data > Create Table > Upload File
2. Fazer upload de todos os arquivos da pasta `Parte2_AnaliseDados/data/`

**OpÃ§Ã£o B - Via dbutils:**
```python
# Copiar arquivos locais para DBFS
dbutils.fs.cp("file:/local/path", "dbfs:/FileStore/cantustore/")
```

### Passo 3: Executar Notebooks

Execute os notebooks na ordem:

1. **00_setup.py** - ConfiguraÃ§Ã£o inicial
2. **01_carregamento_dados.py** - Carregar dados e criar views
3. **02 a 06** - AnÃ¡lises exploratÃ³rias
4. **07 e 08** - RelatÃ³rios
5. **09** - ExportaÃ§Ã£o TXT

---

## ğŸ” Filtros de Dados Aplicados

Para garantir uma anÃ¡lise precisa, os seguintes filtros sÃ£o aplicados automaticamente no **notebook 01**:

### **1. DeduplicaÃ§Ã£o**
- Remove 11.134 PKs duplicados em `tb_carts`
- MantÃ©m apenas o primeiro registro de cada carrinho

### **2. Filtro de Abandono**
- **p_paymentinfo IS NULL**: Carrinho nunca iniciou pagamento
- **p_totalprice > 0**: Carrinho tem produtos adicionados
- **Resultado**: Apenas carrinhos REALMENTE abandonados

### **3. RemoÃ§Ã£o de Outliers**
- Remove carrinhos com valor total > R$ 50.000
- Elimina 4.267 outliers (carrinhos de teste/erro)

### **Dataset Final**
```
Carrinhos abandonados: 905.180
Valor total nÃ£o faturado: R$ 6,27 bilhÃµes
Ticket mÃ©dio: R$ 6.923,89
PerÃ­odo: 2019-12-16 a 2022-07-26 (2,61 anos)

âœ… Todos os valores validados para e-commerce de pneus premium
```

> ğŸ“– **DocumentaÃ§Ã£o completa**: [FILTROS_CARRINHOS_ABANDONADOS.md](Parte2_AnaliseDados/FILTROS_CARRINHOS_ABANDONADOS.md)

---

## ğŸ“Š Resultados Obtidos

### AnÃ¡lises Principais

| AnÃ¡lise | Resultado |
|---------|-----------|
| **Produtos Mais Abandonados** | Top 50 produtos identificados |
| **Duplas de Produtos** | Pares frequentemente abandonados juntos |
| **TendÃªncia de Abandono** | Produtos com crescimento identificados |
| **Produtos Novos** | Performance no primeiro mÃªs analisada |
| **Estados** | ConcentraÃ§Ã£o geogrÃ¡fica de abandonos |

### RelatÃ³rios Gerados

- **Mensal por Produto**: CSV com mÃ©tricas mensais detalhadas
- **DiÃ¡rio**: CSV com mÃ©tricas diÃ¡rias consolidadas
- **TXT Top 50**: Arquivo no formato especificado para anÃ¡lise

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Databricks**: Plataforma de anÃ¡lise de dados
- **PySpark**: Processamento distribuÃ­do de dados
- **SQL**: Queries e anÃ¡lises relacionais
- **Python**: LÃ³gica de negÃ³cio e transformaÃ§Ãµes

---

## ğŸ“ˆ Insights de NegÃ³cio

### Principais Descobertas:

1. **ConcentraÃ§Ã£o de Abandonos**: Identificados produtos com alto volume de abandonos
2. **Produtos Complementares**: Duplas/triplas frequentemente abandonadas juntas sugerem oportunidades de bundle
3. **TendÃªncia Temporal**: Produtos com crescimento de abandono requerem atenÃ§Ã£o
4. **Sazonalidade**: PadrÃµes de abandono por dia da semana e perÃ­odo do mÃªs
5. **DistribuiÃ§Ã£o GeogrÃ¡fica**: Estados com maior concentraÃ§Ã£o para aÃ§Ãµes regionalizadas

### RecomendaÃ§Ãµes:

- Implementar remarketing para produtos com alto abandono
- Criar ofertas de bundle para produtos abandonados juntos
- Investigar causas do aumento de abandono em produtos especÃ­ficos
- Otimizar processo de checkout nos estados com mais abandonos
- Ajustar estratÃ©gias de frete e pagamento por regiÃ£o

---

## ğŸ‘¥ Autor

Projeto desenvolvido como parte da prova tÃ©cnica para a **CantuStore**.

---

## ğŸ“ LicenÃ§a

Este projeto foi desenvolvido para fins educacionais e de avaliaÃ§Ã£o tÃ©cnica.

---

## ğŸ”— Links Ãšteis

- [Databricks Community Edition](https://community.cloud.databricks.com/)
- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)
- [Databricks Documentation](https://docs.databricks.com/)

---

## ğŸ“ Suporte

Para dÃºvidas ou sugestÃµes sobre o projeto, consulte a documentaÃ§Ã£o dos notebooks ou entre em contato.
