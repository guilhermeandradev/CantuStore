# CANTUSTORE - An√°lise de Carrinhos Abandonados

Projeto completo de an√°lise de dados utilizando **Databricks** e **PySpark** para identificar padr√µes de carrinhos abandonados em e-commerce.

---

## üìã Estrutura do Projeto

```
CantuStore/
‚îú‚îÄ‚îÄ Parte1_SQL/                      # Quest√µes SQL
‚îÇ   ‚îú‚îÄ‚îÄ 1.1_campeonato.sql           # Classifica√ß√£o de campeonato
‚îÇ   ‚îú‚îÄ‚îÄ 1.2_comissoes.sql            # An√°lise de comiss√µes
‚îÇ   ‚îî‚îÄ‚îÄ 1.3_colaboradores.sql        # Hierarquia de colaboradores
‚îÇ
‚îú‚îÄ‚îÄ Parte2_AnaliseDados/             # An√°lise de Dados com PySpark
‚îÇ   ‚îú‚îÄ‚îÄ data/                        # Dados (n√£o versionados - upload separado)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tb_carts/                # Diret√≥rio Parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tb_cartentries/          # Diret√≥rio Parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tb_addresses/            # Diret√≥rio Parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tb_paymentinfos/         # Diret√≥rio Parquet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tb_users.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tb_regions.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tb_paymentmodes.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tb_cmssitelp.csv
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ notebooks/                   # Notebooks PySpark (ordem de execu√ß√£o)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 00_setup.py              # Configura√ß√£o inicial
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_carregamento_dados.py # Carregamento + filtros de abandono
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_analise_produtos.py   # Produtos mais abandonados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_analise_duplas.py     # Duplas/trios de produtos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_analise_tendencia.py  # Tend√™ncia temporal de abandono
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 05_analise_produtos_novos.py  # Performance de produtos novos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 06_analise_estados.py    # An√°lise geogr√°fica (estados/regi√µes)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 07_relatorio_produto_mes.py   # Relat√≥rio mensal detalhado
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 08_relatorio_data.py     # Relat√≥rio di√°rio + tend√™ncias
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 09_exportacao_txt.py     # Exporta√ß√£o formato TXT
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ FILTROS_CARRINHOS_ABANDONADOS.md  # Documenta√ß√£o dos filtros
‚îÇ   ‚îú‚îÄ‚îÄ RESUMO_NOTEBOOKS.md          # Resumo de cada notebook
‚îÇ   ‚îî‚îÄ‚îÄ GUIA_DATABRICKS_GITHUB.md    # Guia completo Databricks
‚îÇ
‚îú‚îÄ‚îÄ .gitignore                       # Arquivos ignorados
‚îî‚îÄ‚îÄ README.md                        # Este arquivo
```

---

## üéØ Objetivos do Projeto

### Parte 1: SQL (3 Quest√µes)

1. ‚úÖ **Campeonato**: Calcular classifica√ß√£o de times por pontua√ß√£o (vit√≥ria, empate, derrota)
2. ‚úÖ **Comiss√µes**: Identificar vendedores que receberam >= R$ 1.024 em at√© 3 transfer√™ncias
3. ‚úÖ **Colaboradores**: Encontrar chefe indireto mais baixo na hierarquia que ganha >= 2x o sal√°rio do funcion√°rio

### Parte 2: An√°lise de Dados (PySpark + Databricks)

**5 An√°lises Explorat√≥rias:**
1. ‚úÖ Produtos com mais carrinhos abandonados
2. ‚úÖ Duplas/trios de produtos frequentemente abandonados juntos
3. ‚úÖ Produtos com aumento de abandono ao longo do tempo
4. ‚úÖ Produtos novos e sua performance no primeiro m√™s
5. ‚úÖ Estados com maior concentra√ß√£o de abandonos

**2 Relat√≥rios:**
1. ‚úÖ Relat√≥rio mensal por produto (carrinhos, itens, valor n√£o faturado)
2. ‚úÖ Relat√≥rio di√°rio (carrinhos, itens, valor n√£o faturado + tend√™ncias)

**1 Exporta√ß√£o:**
1. ‚úÖ Arquivo TXT com top 50 carrinhos no formato especificado

---

## üöÄ Como Executar Este Projeto (Guia para Avalia√ß√£o)

### üìå Pr√©-requisitos

- Conta no [Databricks Community Edition](https://community.cloud.databricks.com/) (gratuito)
- Acesso aos arquivos de dados (fornecidos separadamente)

---

### **PASSO 1: Configurar Databricks e Clonar Reposit√≥rio**

#### 1.1 - Acessar Databricks
1. Acesse: https://community.cloud.databricks.com/
2. Fa√ßa login ou crie uma conta gratuita

#### 1.2 - Criar Cluster
1. No menu lateral, clique em **Compute**
2. Clique em **Create Compute**
3. Configure:
   - **Cluster name**: `CantuStore-Cluster` (ou nome de sua prefer√™ncia)
   - **Cluster mode**: Single Node (padr√£o Community Edition)
   - **Databricks runtime version**: **13.3 LTS** ou superior
   - **Node type**: Deixar padr√£o (Community Edition tem apenas uma op√ß√£o)
4. Clique em **Create Compute**
5. Aguarde o cluster ficar com status **"Running"** (√≠cone verde)

#### 1.3 - Clonar Reposit√≥rio do GitHub
1. No menu lateral, clique em **Workspace**
2. Clique em **Repos** (ou **Workspace** ‚Üí **Repos**)
3. Clique em **Add Repo** e clique em "Criar Pasta Git"
4. Preencha:
   - **Git repository URL**: `https://github.com/guilhermeandradev/CantuStore`
   - **Git provider**: GitHub
   - **Repository name**: `CantuStore` (ou deixar auto-preencher)
5. Clique em **Create Repo**
6. Aguarde a clonagem (alguns segundos)

> ‚úÖ **Resultado**: Voc√™ ver√° a estrutura completa do projeto em `Workspace ‚Üí Repos ‚Üí CantuStore`

---

### **PASSO 2: Upload dos Dados**

Os arquivos de dados **n√£o est√£o no GitHub** (`.gitignore`). Voc√™ precisa fazer upload manual.

#### 2.1 - Criar Volume para os Dados
1. No menu lateral, clique em **Catalog**
2. Navegue at√©: **workspace** (ou **main**) ‚Üí **default**
3. Clique nos 3 pontinhos (...) ao lado de **default** ‚Üí **Create** ‚Üí **Volume**
4. Preencha:
   - **Name**: `cantustore_data`
   - **Schema**: `default`
   - **Catalog**: `workspace` (ou o que estiver selecionado)
5. Clique em **Create**

> üìç **Caminho criado**: `/Volumes/workspace/default/cantustore_data/`

#### 2.2 - Fazer Upload dos Arquivos
1. Clique no Volume **cantustore_data** que voc√™ acabou de criar
2. Clique em **Upload Files** (bot√£o no canto superior direito)
3. Fa√ßa upload dos seguintes arquivos (fornecidos separadamente):

**Diret√≥rios Parquet** (fazer upload de cada diret√≥rio):
- `tb_carts/` (cont√©m arquivos .parquet)
- `tb_cartentries/` (cont√©m arquivos .parquet)
- `tb_addresses/` (cont√©m arquivos .parquet)
- `tb_paymentinfos/` (cont√©m arquivos .parquet)

**Arquivos CSV** (fazer upload individual):
- `tb_users.csv`
- `tb_regions.csv`
- `tb_paymentmodes.csv`
- `tb_cmssitelp.csv`

> üí° **Dica**: No Databricks, voc√™ pode arrastar e soltar os arquivos diretamente na interface de upload.

#### 2.3 - Verificar Upload
Ap√≥s o upload, voc√™ deve ver no Volume:
```
cantustore_data/
‚îú‚îÄ‚îÄ tb_carts/
‚îú‚îÄ‚îÄ tb_cartentries/
‚îú‚îÄ‚îÄ tb_addresses/
‚îú‚îÄ‚îÄ tb_paymentinfos/
‚îú‚îÄ‚îÄ tb_users.csv
‚îú‚îÄ‚îÄ tb_regions.csv
‚îú‚îÄ‚îÄ tb_paymentmodes.csv
‚îî‚îÄ‚îÄ tb_cmssitelp.csv
```

---

### **PASSO 3: Ajustar Configura√ß√£o (Se Necess√°rio)**

#### 3.1 - Verificar Caminho dos Dados
1. Navegue at√©: **Workspace** ‚Üí **Repos** ‚Üí **CantuStore** ‚Üí **Parte2_AnaliseDados** ‚Üí **notebooks**
2. Abra o notebook **`00_setup.py`**
3. Localize a linha 23 (aproximadamente):
   ```python
   BASE_PATH = "/Volumes/workspace/default/cantustore_data/"
   ```
4. **Se voc√™ usou outro Catalog ou Schema**, ajuste o caminho:
   - Exemplo: `/Volumes/main/default/cantustore_data/`
   - Exemplo: `/Volumes/workspace/seu_schema/cantustore_data/`

5. **Se o caminho estiver correto**, n√£o √© necess√°rio alterar nada

> ‚ö†Ô∏è **Importante**: Certifique-se de que o caminho termina com `/`

---

### **PASSO 4: Executar os Notebooks (ORDEM OBRIGAT√ìRIA)**

#### 4.1 - Anexar Cluster aos Notebooks
Antes de executar, certifique-se de que o cluster est√° anexado:
1. Abra qualquer notebook
2. No topo do notebook, voc√™ ver√° **"Detached"** ou o nome de um cluster
3. Se estiver **"Detached"**, clique e selecione **CantuStore-Cluster**
4. Aguarde a conex√£o (alguns segundos)

#### 4.2 - Executar na Ordem
Execute os notebooks **UM POR VEZ**, na ordem abaixo:

| Ordem | Notebook | Descri√ß√£o | Comando |
|-------|----------|-----------|---------|
| 1 | `00_setup.py` | Configura√ß√£o inicial (imports, paths, fun√ß√µes) | **Run All** |
| 2 | `01_carregamento_dados.py` | Carrega dados + aplica filtros de abandono | **Run All** |
| 3 | `02_analise_produtos.py` | Top produtos mais abandonados | **Run All** |
| 4 | `03_analise_duplas.py` | Duplas/trios de produtos abandonados | **Run All** |
| 5 | `04_analise_tendencia.py` | Tend√™ncia temporal de abandono | **Run All** |
| 6 | `05_analise_produtos_novos.py` | Performance de produtos novos | **Run All** |
| 7 | `06_analise_estados.py` | An√°lise geogr√°fica (estados) | **Run All** |
| 8 | `07_relatorio_produto_mes.py` | Relat√≥rio mensal por produto | **Run All** |
| 9 | `08_relatorio_data.py` | Relat√≥rio di√°rio + tend√™ncias | **Run All** |
| 10 | `09_exportacao_txt.py` | Exporta√ß√£o formato TXT (top 50) | **Run All** |

#### 4.3 - Como Executar "Run All"
1. Abra o notebook
2. No menu superior, clique em **Run All** (ou pressione `Ctrl + Shift + Enter`)
3. Aguarde a execu√ß√£o completa (voc√™ ver√° os resultados aparecerem)
4. Passe para o pr√≥ximo notebook

> ‚è±Ô∏è **Tempo estimado**: 
> - Notebooks 00-01: ~2-3 minutos cada
> - Notebooks 02-09: ~1-2 minutos cada
> - **Total**: ~15-20 minutos para executar todos

---

### **PASSO 5: Validar Resultados**

#### 5.1 - Verificar Carregamento de Dados (Notebook 01)
Ap√≥s executar `01_carregamento_dados.py`, role at√© o final. Voc√™ deve ver:
```
================================================================================
ESTAT√çSTICAS DO DATASET FINAL
================================================================================

Carrinhos abandonados: [n√∫mero]
Total de itens: [n√∫mero]
Valor total n√£o faturado: R$ [valor]

Ticket m√©dio: R$ [valor]
Itens por carrinho: [n√∫mero]
Pre√ßo m√©dio por item: R$ [valor]
```

‚úÖ **Se voc√™ v√™ esta mensagem**: Dados carregados e filtrados corretamente!

#### 5.2 - Verificar An√°lises (Notebooks 02-09)
Cada notebook gera:
- Tabelas e gr√°ficos com os resultados
- Estat√≠sticas e insights
- Arquivos CSV salvos no caminho de output

#### 5.3 - Localizar Arquivos Gerados
Os resultados s√£o salvos em:
```
/Volumes/workspace/default/cantustore_data/resultados/
```

Para visualizar:
1. **Catalog** ‚Üí **workspace** ‚Üí **default** ‚Üí **cantustore_data** ‚Üí **resultados**
2. Ou navegue pelo c√≥digo dos notebooks para ver os outputs inline

---

## üîç Filtros de Dados Aplicados

O projeto aplica **filtros autom√°ticos** no notebook 01 para garantir an√°lise precisa:

### **1. Deduplica√ß√£o**
- Remove **11.134 PKs duplicados** em `tb_carts`
- Mant√©m apenas o primeiro registro de cada carrinho

### **2. Filtro de Abandono**
- **p_paymentinfo IS NULL**: Carrinho nunca iniciou pagamento
- **p_totalprice > 0**: Carrinho tem produtos adicionados
- **Resultado**: Apenas carrinhos REALMENTE abandonados

### **3. Remo√ß√£o de Outliers**
- Remove carrinhos com valor total > R$ 50.000
- Elimina **4.267 outliers** (carrinhos de teste/erro)

### **üìä Dataset Final (Ap√≥s Filtros)**

```
Per√≠odo: 2019-12-16 a 2022-07-26 (2,61 anos / 953 dias)

Carrinhos abandonados: 905.180
Total de itens abandonados: 2.769.758
Valor total n√£o faturado: R$ 6.267.369.294,36

Ticket m√©dio: R$ 6.923,89
Itens por carrinho: 3,06 pneus
Pre√ßo m√©dio por item: R$ 2.262,79

Abandonos por dia: 950 carrinhos
Valor n√£o faturado por dia: R$ 6.576.463,06

‚úÖ Todos os valores validados para e-commerce de pneus premium
```

> üìñ **Documenta√ß√£o completa dos filtros**: [FILTROS_CARRINHOS_ABANDONADOS.md](Parte2_AnaliseDados/FILTROS_CARRINHOS_ABANDONADOS.md)

---

## üõ†Ô∏è Tecnologias Utilizadas

- **Databricks**: Plataforma de an√°lise de dados em nuvem
- **PySpark**: Processamento distribu√≠do de grandes volumes de dados
- **SQL**: Queries e an√°lises relacionais
- **Python**: L√≥gica de neg√≥cio e transforma√ß√µes
- **GitHub**: Versionamento e colabora√ß√£o

---

## üìä Estrutura das An√°lises

### **An√°lises Explorat√≥rias (Notebooks 02-06)**
| An√°lise | Objetivo | Output |
|---------|----------|--------|
| **Produtos** | Identificar produtos com mais abandonos | Top 50 produtos + estat√≠sticas |
| **Duplas** | Produtos frequentemente abandonados juntos | Top duplas e trios |
| **Tend√™ncia** | Crescimento/queda de abandono ao longo do tempo | Produtos com mudan√ßa de padr√£o |
| **Produtos Novos** | Performance de lan√ßamentos | Abandono no primeiro m√™s |
| **Estados** | Concentra√ß√£o geogr√°fica | Ranking por estado + regi√£o |

### **Relat√≥rios (Notebooks 07-08)**
| Relat√≥rio | Granularidade | Colunas |
|-----------|---------------|---------|
| **Mensal** | Produto + M√™s | qtd_carrinhos, qtd_itens, valor_nao_faturado |
| **Di√°rio** | Data | qtd_carrinhos, qtd_itens, valor_nao_faturado |

### **Exporta√ß√£o (Notebook 09)**
- Formato: TXT
- Conte√∫do: Top 50 carrinhos por valor
- Layout: Especificado conforme requisitos

---

## üìà Insights de Neg√≥cio Esperados

### **Principais Descobertas Poss√≠veis:**
1. **Produtos Cr√≠ticos**: Identifica√ß√£o de produtos com alto volume de abandono
2. **Complementaridade**: Duplas/trios abandonados juntos ‚Üí oportunidades de bundle
3. **Padr√µes Temporais**: Sazonalidade, dia da semana, per√≠odo do m√™s
4. **Distribui√ß√£o Geogr√°fica**: Estados/regi√µes com maior abandono
5. **Performance de Novos Produtos**: Taxa de abandono em lan√ßamentos

### **Recomenda√ß√µes de Neg√≥cio:**
- Implementar remarketing para produtos com alto abandono
- Criar ofertas de bundle para produtos abandonados juntos
- Investigar causas de aumento de abandono em produtos espec√≠ficos
- Otimizar checkout nos estados com mais abandonos
- Ajustar estrat√©gias de frete/pagamento por regi√£o

---

## üìö Documenta√ß√£o Adicional

- **[FILTROS_CARRINHOS_ABANDONADOS.md](Parte2_AnaliseDados/FILTROS_CARRINHOS_ABANDONADOS.md)**: Explica√ß√£o detalhada dos filtros e valida√ß√µes
- **[RESUMO_NOTEBOOKS.md](Parte2_AnaliseDados/RESUMO_NOTEBOOKS.md)**: Resumo do objetivo de cada notebook
- **[GUIA_DATABRICKS_GITHUB.md](Parte2_AnaliseDados/GUIA_DATABRICKS_GITHUB.md)**: Guia completo de integra√ß√£o Databricks + GitHub

---

## ‚ùì Troubleshooting

### **Problema: "Path does not exist"**
**Causa**: Caminho dos dados incorreto  
**Solu√ß√£o**: Verificar `BASE_PATH` no `00_setup.py` (linha 23) e ajustar conforme o caminho do seu Volume

### **Problema: "Unable to attach cluster"**
**Causa**: Cluster n√£o est√° rodando  
**Solu√ß√£o**: 
1. V√° em **Compute**
2. Verifique se o cluster est√° **"Running"**
3. Se n√£o, clique em **Start**

### **Problema: "countDistinct not defined"**
**Causa**: Notebook 00 n√£o foi executado  
**Solu√ß√£o**: Execute `00_setup.py` primeiro (imports e configura√ß√µes)

### **Problema: "DataFrame not found"**
**Causa**: Notebook 01 n√£o foi executado  
**Solu√ß√£o**: Execute `01_carregamento_dados.py` antes dos outros

### **Problema: Valores parecem incorretos**
**Causa**: Executou notebooks fora de ordem ou n√£o executou 01  
**Solu√ß√£o**: 
1. **Clear State & Outputs** em todos os notebooks
2. **Restart Cluster**
3. Re-executar na ordem (00 ‚Üí 01 ‚Üí 02... ‚Üí 09)

---

## üîó Links √öteis

- [Databricks Community Edition](https://community.cloud.databricks.com/) - Plataforma gratuita
- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/) - Documenta√ß√£o oficial PySpark
- [Databricks Documentation](https://docs.databricks.com/) - Guias e tutoriais Databricks

---

## üìÑ Relat√≥rio T√©cnico

Para uma vis√£o executiva completa do projeto, consulte:

üìã **[RELATORIO_TECNICO_CANTUSTORE.md](RELATORIO_TECNICO_CANTUSTORE.md)**

O relat√≥rio cont√©m:
- Explica√ß√£o detalhada de todas as solu√ß√µes SQL
- Arquitetura completa da an√°lise de dados
- Insights e recomenda√ß√µes de neg√≥cio
- M√©tricas de qualidade e desafios superados

---

**CantuStore - Plataforma de tecnologia e log√≠stica em pneus**  
*Se o assunto √© pneu, voc√™ resolve aqui.*
